Wed Feb 22 03:19:38 2023
dataset=mnist lr=0.0002 batch_size=128 epochs=20
checkpoint=save/mnist
train_further=False old_checkpoint=None
Beta scheduling : time_steps=1000 beta_0=0.0001 beta_T=0.02
U-Net Parameters : ch=32 groups=8 scale=(1, 2, 4, 8) add_attn=(2,) dropout_rate=0.1
Loaded mnist dataset
Epoch: 1
Loss after 1 epoch(s):  0.15319933
Epoch: 2
Loss after 2 epoch(s):  0.041216668
Epoch: 3
Loss after 3 epoch(s):  0.032493256
Epoch: 4
Loss after 4 epoch(s):  0.02915461
Epoch: 5
Loss after 5 epoch(s):  0.026902221
Epoch: 6
Loss after 6 epoch(s):  0.024955573
Epoch: 7
Loss after 7 epoch(s):  0.023659617
Epoch: 8
Loss after 8 epoch(s):  0.02238338
Epoch: 9
Loss after 9 epoch(s):  0.022063233
Epoch: 10
Loss after 10 epoch(s):  0.02092821
Epoch: 11
Loss after 11 epoch(s):  0.020633109
Epoch: 12
Loss after 12 epoch(s):  0.019917801
Epoch: 13
Loss after 13 epoch(s):  0.01952683
Epoch: 14
Loss after 14 epoch(s):  0.01896597
Epoch: 15
Loss after 15 epoch(s):  0.018980244
Epoch: 16
Loss after 16 epoch(s):  0.018642707
Epoch: 17
Loss after 17 epoch(s):  0.018227972
Epoch: 18
Loss after 18 epoch(s):  0.018128626
Epoch: 19
Loss after 19 epoch(s):  0.017947048
Epoch: 20
Loss after 20 epoch(s):  0.017709894
Checkpoint saved after 20 epochs at save/mnist
Finished training after 20 epochs

